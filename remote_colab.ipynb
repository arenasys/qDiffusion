{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whoxg9A87Zl7"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "import IPython.display\n",
        "import os\n",
        "import sys\n",
        "\n",
        "if not os.path.exists(\"/content/sd-inference-server\"):\n",
        "    !git clone https://github.com/arenasys/sd-inference-server.git\n",
        "\n",
        "%cd /content/sd-inference-server\n",
        "!git pull\n",
        "\n",
        "model_folder = \"/content/sd-inference-server/models\"\n",
        "try:\n",
        "    # decline the popup to use the local folder ^\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    model_folder = \"/content/drive/My Drive/qDiffusion/models\"\n",
        "    if not os.path.exists(model_folder):\n",
        "        !mkdir '/content/drive/My Drive/qDiffusion' -p\n",
        "        !cp -r 'models/' '/content/drive/My Drive/qDiffusion/'\n",
        "except Exception as e:\n",
        "    pass\n",
        "\n",
        "if not os.path.exists(\"venv\"):\n",
        "    !mkdir venv\n",
        "    !pip uninstall -q -y tensorflow\n",
        "    !pip install -q diffusers==0.21.0 k_diffusion==0.0.15 basicsr==1.4.2 lark==1.1.5 transformers==4.29.2 websockets==11.0.3 bson==0.5.10 mega.py==1.0.8 pytorch-lightning==2.0.2 timm==0.9.2 tomesd==0.1.3 pycloudflared==0.2.0 segment-anything==1.0 geffnet==1.0.2 \n",
        "    IPython.display.clear_output()\n",
        "\n",
        "    !apt -y update -qq\n",
        "    !wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\n",
        "    %env LD_PRELOAD=/content/libtcmalloc_minimal.so.4\n",
        "    IPython.display.clear_output()\n",
        "\n",
        "if not sys.path[0] == \"/content/sd-inference-server/\":\n",
        "    sys.path.insert(0, \"/content/sd-inference-server/\")\n",
        "\n",
        "from pycloudflared import try_cloudflare\n",
        "tunnel_url = try_cloudflare(port=28888, verbose=False)\n",
        "endpoint_url = tunnel_url.tunnel.replace(\"https\", \"wss\")\n",
        "\n",
        "!python remote.py --models \"$model_folder\" --endpoint \"$endpoint_url\"\n",
        "\n",
        "try_cloudflare.terminate(28888)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
