{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whoxg9A87Zl7"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/arenasys/sd-inference-server.git\n",
        "%cd /content/sd-inference-server\n",
        "\n",
        "model_folder = \"./models\"\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    import os\n",
        "    drive.mount('/content/drive')\n",
        "    model_folder = \"/content/drive/My Drive/qDiffusion/models\"\n",
        "    !mkdir '/content/drive/My Drive/qDiffusion' -p\n",
        "    if not os.path.exists('/content/drive/My Drive/qDiffusion/models'):\n",
        "        !cp -r 'models/' '/content/drive/My Drive/qDiffusion/'\n",
        "except Exception as e:\n",
        "    pass\n",
        "\n",
        "!curl -OJL https://huggingface.co/datasets/arenasys/qDiffusion/resolve/main/cached_venv.tar\n",
        "!tar xf cached_venv.tar\n",
        "!mv cached_venv venv\n",
        "!rm cached_venv.tar\n",
        "!pip install websockets==11.0\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/sd-inference-server/venv/lib/python3.9/site-packages\")\n",
        "sys.path.insert(0, \"/content/sd-inference-server/\")\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import attention\n",
        "import storage\n",
        "import wrapper\n",
        "import string\n",
        "import time\n",
        "from ws_server import Server\n",
        "\n",
        "attention.use_optimized_attention()\n",
        "\n",
        "model_storage = storage.ModelStorage(model_folder, torch.float16, torch.float32)\n",
        "params = wrapper.GenerationParameters(model_storage, torch.device(\"cuda\"))\n",
        "\n",
        "password = ''.join(random.SystemRandom().choice(string.ascii_letters + string.digits) for _ in range(8))\n",
        "\n",
        "server = Server(params, \"127.0.0.1\", \"28888\", password)\n",
        "server.start()\n",
        "\n",
        "from pycloudflared import try_cloudflare\n",
        "tunnel_url = try_cloudflare(port=28888, verbose=False)\n",
        "print(\"ENDPOINT: \", tunnel_url.tunnel.replace(\"https\", \"wss\"))\n",
        "print(\"PASSWORD: \", password)\n",
        "\n",
        "while True:\n",
        "    time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
