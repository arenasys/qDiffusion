{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whoxg9A87Zl7"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "import IPython.display\n",
        "import os\n",
        "import sys\n",
        "\n",
        "if not os.path.exists(\"/content/sd-inference-server\"):\n",
        "    !git clone https://github.com/arenasys/sd-inference-server.git\n",
        "    !wget http://launchpadlibrarian.net/367274644/libgoogle-perftools-dev_2.5-2.2ubuntu3_amd64.deb\n",
        "    !wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/google-perftools_2.5-2.2ubuntu3_all.deb\n",
        "    !wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libtcmalloc-minimal4_2.5-2.2ubuntu3_amd64.deb\n",
        "    !wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libgoogle-perftools4_2.5-2.2ubuntu3_amd64.deb\n",
        "    !apt install -qq libunwind8-dev\n",
        "    !dpkg -i *.deb\n",
        "    %env LD_PRELOAD=libtcmalloc.so\n",
        "    !rm *.deb\n",
        "    IPython.display.clear_output()\n",
        "\n",
        "%cd /content/sd-inference-server\n",
        "model_folder = \"./models\"\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    model_folder = \"/content/drive/My Drive/qDiffusion/models\"\n",
        "    if not os.path.exists(model_folder):\n",
        "        !mkdir '/content/drive/My Drive/qDiffusion' -p\n",
        "        !cp -r 'models/' '/content/drive/My Drive/qDiffusion/'\n",
        "except Exception as e:\n",
        "    pass\n",
        "\n",
        "if not os.path.exists(\"venv\"):\n",
        "    !curl -OJL https://huggingface.co/datasets/arenasys/qDiffusion/resolve/main/cached_venv.tar\n",
        "    !tar xf cached_venv.tar; mv cached_venv venv; rm cached_venv.tar\n",
        "    !source /content/sd-inference-server/venv/bin/activate; pip3 install pytorch-lightning\n",
        "    !source /content/sd-inference-server/venv/bin/activate; pip3 install websockets==11.0\n",
        "    IPython.display.clear_output()\n",
        "\n",
        "if not sys.path[0] == \"/content/sd-inference-server/\":\n",
        "    sys.path.insert(0, \"/content/sd-inference-server/venv/lib/python3.9/site-packages\")\n",
        "    sys.path.insert(0, \"/content/sd-inference-server/\")\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import attention\n",
        "import storage\n",
        "import wrapper\n",
        "import string\n",
        "import time\n",
        "from server import Server\n",
        "\n",
        "attention.use_optimized_attention()\n",
        "\n",
        "model_storage = storage.ModelStorage(model_folder, torch.float16, torch.float32)\n",
        "params = wrapper.GenerationParameters(model_storage, torch.device(\"cuda\"))\n",
        "\n",
        "password = ''.join(random.SystemRandom().choice(string.ascii_letters + string.digits) for _ in range(8))\n",
        "\n",
        "server = Server(params, \"127.0.0.1\", \"28888\", password)\n",
        "server.start()\n",
        "\n",
        "from pycloudflared import try_cloudflare\n",
        "tunnel_url = try_cloudflare(port=28888, verbose=False)\n",
        "print(\"ENDPOINT: \", tunnel_url.tunnel.replace(\"https\", \"wss\"))\n",
        "print(\"PASSWORD: \", password)\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except:\n",
        "    server.stop()\n",
        "    try_cloudflare.terminate(28888)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
